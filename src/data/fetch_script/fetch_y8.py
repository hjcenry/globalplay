#!/usr/bin/env python3
"""
Y8 Games çˆ¬è™«è„šæœ¬
æŠ“å– zh.y8.com çƒ­é—¨æ¸¸æˆæ•°æ®ï¼Œç”Ÿæˆç¬¦åˆé¡¹ç›®æ ¼å¼çš„æ¸¸æˆæ•°æ®
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import re
import os
from urllib.parse import urljoin, urlparse
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

class Y8GamesCrawler:
    def __init__(self):
        self.base_url = "https://www.y8.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9,zh;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        self.games = []
        self.setup_selenium()
        
    def setup_selenium(self):
        """è®¾ç½® Selenium WebDriver"""
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--disable-web-security')
        chrome_options.add_argument('--disable-features=VizDisplayCompositor')
        chrome_options.add_argument('--disable-logging')
        chrome_options.add_argument('--silent')
        chrome_options.add_argument('--lang=en-US')  # å¼ºåˆ¶è‹±æ–‡
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36')
        
        # ç¦ç”¨å›¾ç‰‡åŠ è½½ä»¥æé«˜é€Ÿåº¦ï¼Œå¹¶è®¾ç½®è¯­è¨€åå¥½
        prefs = {
            "profile.managed_default_content_settings.images": 2,
            "profile.default_content_setting_values.notifications": 2,
            "intl.accept_languages": "en-US,en"  # å¼ºåˆ¶è‹±æ–‡è¯­è¨€åå¥½
        }
        chrome_options.add_experimental_option("prefs", prefs)
        
        try:
            self.driver = webdriver.Chrome(options=chrome_options)
            print("âœ… Chrome WebDriver åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Chrome WebDriver åˆå§‹åŒ–å¤±è´¥: {e}")
            print("ğŸ’¡ è¯·ç¡®ä¿ ChromeDriver ç‰ˆæœ¬ä¸ Chrome æµè§ˆå™¨ç‰ˆæœ¬å…¼å®¹")
            raise

    def extract_game_cards(self, page_num):
        """ä»æŒ‡å®šé¡µé¢æå–æ¸¸æˆå¡ç‰‡ä¿¡æ¯"""
        url = f"https://www.y8.com/popular/games?page={page_num}&hl=en"
        print(f"ğŸ” æ­£åœ¨æŠ“å–ç¬¬ {page_num} é¡µ: {url}")
        
        try:
            self.driver.get(url)
            # ç­‰å¾…é¡µé¢åŠ è½½
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "img.thumb.playable"))
            )
            time.sleep(2)  # é¢å¤–ç­‰å¾…ç¡®ä¿å›¾ç‰‡åŠ è½½
            
            # è·å–é¡µé¢æºç 
            html = self.driver.page_source
            soup = BeautifulSoup(html, 'html.parser')
            
            # æŸ¥æ‰¾æ¸¸æˆå¡ç‰‡
            game_cards = soup.find_all('img', class_='thumb playable')
            print(f"ğŸ“‹ åœ¨ç¬¬ {page_num} é¡µæ‰¾åˆ° {len(game_cards)} ä¸ªæ¸¸æˆ")
            
            page_games = []
            for card in game_cards:
                try:
                    # æå–æ¸¸æˆä¿¡æ¯
                    game_title = card.get('alt', '').strip()
                    if not game_title:
                        continue
                        
                    # è·å–å›¾ç‰‡é“¾æ¥
                    thumbnail = card.get('src') or card.get('data-src', '')
                    
                    # ä»çˆ¶å…ƒç´ è·å–æ¸¸æˆé“¾æ¥
                    parent_link = card.find_parent('a')
                    if not parent_link:
                        continue
                        
                    game_link = parent_link.get('href', '')
                    if game_link.startswith('/'):
                        game_link = urljoin(self.base_url, game_link)
                    
                    # æå–æ¸¸æˆ slug
                    slug = game_link.split('/')[-1] if game_link else ''
                    
                    if game_title and game_link and slug:
                        page_games.append({
                            'title': game_title,
                            'slug': slug,
                            'game_link': game_link,
                            'thumbnail': thumbnail
                        })
                        
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†æ¸¸æˆå¡ç‰‡æ—¶å‡ºé”™: {e}")
                    continue
            
            return page_games
            
        except TimeoutException:
            print(f"âŒ ç¬¬ {page_num} é¡µåŠ è½½è¶…æ—¶")
            return []
        except Exception as e:
            print(f"âŒ æŠ“å–ç¬¬ {page_num} é¡µæ—¶å‡ºé”™: {e}")
            return []

    def extract_game_details(self, game_info):
        """ä»æ¸¸æˆè¯¦æƒ…é¡µæå–è¯¦ç»†ä¿¡æ¯"""
        game_url = game_info['game_link']
        print(f"ğŸ® æ­£åœ¨è·å–æ¸¸æˆè¯¦æƒ…: {game_info['title']}")
        
        try:
            self.driver.get(game_url)
            # ç­‰å¾…é¡µé¢åŠ è½½
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            time.sleep(2)
            
            html = self.driver.page_source
            soup = BeautifulSoup(html, 'html.parser')
            
            # æŸ¥æ‰¾ iframe
            iframe = soup.find('iframe', {'id': 'item-direct-container'})
            if not iframe:
                iframe = soup.find('iframe', class_='item-direct-container')
            
            if not iframe:
                print(f"âš ï¸ æœªæ‰¾åˆ°æ¸¸æˆ iframe: {game_info['title']}")
                return None
                
            iframe_src = iframe.get('src') or iframe.get('data-src', '')
            if not iframe_src:
                print(f"âš ï¸ iframe æ— æœ‰æ•ˆ src: {game_info['title']}")
                return None
            
            # æå–æ¸¸æˆæè¿°
            description = ""
            desc_selectors = [
                'h2.ltr.description',  # æ­£ç¡®çš„æ¸¸æˆæè¿°é€‰æ‹©å™¨
                'div.item-description',
                'div.description',
                '.game-description',
                'meta[name="description"]'
            ]
            
            for selector in desc_selectors:
                if selector.startswith('meta'):
                    desc_elem = soup.find('meta', {'name': 'description'})
                    if desc_elem:
                        description = desc_elem.get('content', '').strip()
                        break
                else:
                    desc_elem = soup.select_one(selector)
                    if desc_elem:
                        description = desc_elem.get_text().strip()
                        break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æè¿°ï¼Œä½¿ç”¨é»˜è®¤æè¿°
            if not description:
                description = f"Play {game_info['title']} - an exciting game from Y8!"
            
            # æå–è¯„åˆ† (å¦‚æœæœ‰çš„è¯)
            rating = 4.0  # é»˜è®¤è¯„åˆ†
            rating_selectors = [
                '.rating-value',
                '.score',
                '.rating'
            ]
            
            for selector in rating_selectors:
                rating_elem = soup.select_one(selector)
                if rating_elem:
                    try:
                        rating_text = rating_elem.get_text().strip()
                        rating_match = re.search(r'(\d+\.?\d*)', rating_text)
                        if rating_match:
                            rating = float(rating_match.group(1))
                            if rating > 5:  # å¦‚æœæ˜¯ç™¾åˆ†åˆ¶ï¼Œè½¬æ¢ä¸º5åˆ†åˆ¶
                                rating = rating / 20
                            break
                    except:
                        continue
            
            # æå–æ¸¸æˆåˆ†ç±»
            category = "action"  # é»˜è®¤åˆ†ç±»
            category_selectors = [
                '.category',
                '.genre',
                'meta[property="game:category"]'
            ]
            
            for selector in category_selectors:
                if selector.startswith('meta'):
                    cat_elem = soup.find('meta', {'property': 'game:category'})
                    if cat_elem:
                        category = cat_elem.get('content', '').lower()
                        break
                else:
                    cat_elem = soup.select_one(selector)
                    if cat_elem:
                        category = cat_elem.get_text().strip().lower()
                        break
            
            # æ˜ å°„åˆ°æˆ‘ä»¬çš„åˆ†ç±»
            category_mapping = {
                'action': 'action',
                'puzzle': 'puzzle', 
                'strategy': 'strategy',
                'racing': 'racing',
                'adventure': 'adventure',
                'shooting': 'shooting',
                'sport': 'action',
                'arcade': 'action',
                'platform': 'action',
                'rpg': 'adventure'
            }
            
            for key in category_mapping:
                if key in category:
                    category = category_mapping[key]
                    break
            else:
                category = 'action'  # é»˜è®¤åˆ†ç±»
            
            # ç”Ÿæˆç®€çŸ­æè¿°
            if description and len(description) > 150:
                # ä»å®Œæ•´æè¿°ä¸­æå–å‰150ä¸ªå­—ç¬¦ï¼Œå¹¶åœ¨å•è¯è¾¹ç•Œæˆªæ–­
                short_desc = description[:147] + "..."
                # å°è¯•åœ¨å¥å­ç»“æŸå¤„æˆªæ–­
                if '. ' in short_desc:
                    sentences = short_desc.split('. ')
                    if len(sentences) > 1:
                        short_desc = sentences[0] + '.'
            else:
                short_desc = description if description else f"Play {game_info['title']} - an exciting {category} game from Y8!"
            
            # ç”Ÿæˆæ¸¸æˆæ•°æ®
            game_data = {
                'id': game_info['slug'],
                'slug': game_info['slug'],
                'title': game_info['title'],
                'description': description,
                'shortDescription': short_desc,
                'category': category,
                'thumbnail': f"/images/games/y8/{game_info['slug']}.jpg",
                'gameUrl': iframe_src,
                'rating': round(rating, 1),
                'playCount': self.generate_play_count(),
                'tags': [category, "y8", "popular"],
                'controls': 'Keyboard & Mouse',
                'featured': False,
                'trending': True,
                'isNew': False
            }
            
            return game_data
            
        except Exception as e:
            print(f"âŒ è·å–æ¸¸æˆè¯¦æƒ…å¤±è´¥ {game_info['title']}: {e}")
            return None

    def generate_play_count(self):
        """ç”Ÿæˆéšæœºçš„æ¸¸æˆæ¬¡æ•°"""
        import random
        return random.randint(15000, 200000)

    def download_image(self, image_url, save_path):
        """ä¸‹è½½æ¸¸æˆå°é¢å›¾ç‰‡"""
        try:
            if not image_url:
                return False
                
            response = self.session.get(image_url, timeout=10)
            response.raise_for_status()
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            with open(save_path, 'wb') as f:
                f.write(response.content)
            
            print(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {os.path.basename(save_path)}")
            return True
            
        except Exception as e:
            print(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥ {image_url}: {e}")
            return False

    def crawl_all_pages(self, start_page=1, end_page=9):
        """çˆ¬å–æ‰€æœ‰é¡µé¢çš„æ¸¸æˆ"""
        print(f"ğŸš€ å¼€å§‹çˆ¬å– Y8 æ¸¸æˆç½‘ç«™ (ç¬¬ {start_page}-{end_page} é¡µ)")
        
        all_game_cards = []
        
        # æ­¥éª¤1: æ”¶é›†æ‰€æœ‰æ¸¸æˆå¡ç‰‡ä¿¡æ¯
        for page in range(start_page, end_page + 1):
            page_games = self.extract_game_cards(page)
            all_game_cards.extend(page_games)
            time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        print(f"ğŸ“Š æ€»å…±æ”¶é›†åˆ° {len(all_game_cards)} ä¸ªæ¸¸æˆå¡ç‰‡")
        
        # æ­¥éª¤2: è·å–æ¯ä¸ªæ¸¸æˆçš„è¯¦ç»†ä¿¡æ¯
        successful_games = []
        failed_games = []
        
        for i, game_info in enumerate(all_game_cards, 1):
            print(f"ğŸ“ è¿›åº¦: {i}/{len(all_game_cards)} - {game_info['title']}")
            
            game_data = self.extract_game_details(game_info)
            if game_data:
                # ä¸‹è½½å›¾ç‰‡
                if game_info['thumbnail']:
                    image_path = f"public/images/games/y8/{game_info['slug']}.jpg"
                    self.download_image(game_info['thumbnail'], image_path)
                
                successful_games.append(game_data)
                print(f"âœ… æˆåŠŸå¤„ç†: {game_info['title']}")
            else:
                failed_games.append(game_info)
                print(f"âŒ å¤„ç†å¤±è´¥: {game_info['title']}")
            
            time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        self.games = successful_games
        
        print(f"\nğŸ¯ çˆ¬å–å®Œæˆ!")
        print(f"âœ… æˆåŠŸ: {len(successful_games)} ä¸ªæ¸¸æˆ")
        print(f"âŒ å¤±è´¥: {len(failed_games)} ä¸ªæ¸¸æˆ")
        
        if failed_games:
            print("\nâŒ å¤±è´¥çš„æ¸¸æˆ:")
            for game in failed_games:
                print(f"  - {game['title']}")

    def save_to_json(self, filename="y8_games.json"):
        """ä¿å­˜æ•°æ®ä¸º JSON æ–‡ä»¶"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.games, f, ensure_ascii=False, indent=2)
            print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

    def generate_typescript_data(self, filename="y8_games_data.ts"):
        """ç”Ÿæˆ TypeScript æ ¼å¼çš„æ•°æ®æ–‡ä»¶"""
        try:
            ts_content = """// Y8 Games data for GlobalPlay Games Website
// Auto-generated from Y8 crawler

export const y8Games = """
            
            ts_content += json.dumps(self.games, ensure_ascii=False, indent=2)
            ts_content += ";\n"
            
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(ts_content)
            
            print(f"âœ… TypeScript æ•°æ®å·²ä¿å­˜åˆ° {filename}")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆ TypeScript æ–‡ä»¶å¤±è´¥: {e}")

    def close(self):
        """å…³é—­ WebDriver"""
        if hasattr(self, 'driver'):
            self.driver.quit()
            print("ğŸ”’ WebDriver å·²å…³é—­")

def main():
    crawler = Y8GamesCrawler()
    
    try:
        # çˆ¬å–æ‰€æœ‰é¡µé¢ (1-9é¡µ)
        crawler.crawl_all_pages(start_page=1, end_page=9)
        
        # ä¿å­˜æ•°æ®
        crawler.save_to_json("y8_games.json")
        crawler.generate_typescript_data("y8_games_data.ts")
        
        print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆ! å…±çˆ¬å– {len(crawler.games)} ä¸ª Y8 æ¸¸æˆ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ å‡ºç°é”™è¯¯: {e}")
    finally:
        crawler.close()

if __name__ == "__main__":
    main() 